[
  {
    "objectID": "assignments/index.html",
    "href": "assignments/index.html",
    "title": "ordinal regression",
    "section": "",
    "text": "If you are fitting a model, display the model output in a neatly formatted table. (The tidy and kable functions can help!)\nIf you are creating a plot, use clear labels for all axes, titles, etc.\nIf you are using Github, don’t forget to commit and push your work to to it regularly, at least after each exercise. Write short and informative commit messages. Else, if you are submitting on Canvas, make sure that the version you submit is the latest, and that it runs/knits without any errors.\nWhen you’re done, we should be able to knit the final version of the QMD in your GitHub as a HTML."
  },
  {
    "objectID": "assignments/index.html#instructions",
    "href": "assignments/index.html#instructions",
    "title": "ordinal regression",
    "section": "",
    "text": "If you are fitting a model, display the model output in a neatly formatted table. (The tidy and kable functions can help!)\nIf you are creating a plot, use clear labels for all axes, titles, etc.\nIf you are using Github, don’t forget to commit and push your work to to it regularly, at least after each exercise. Write short and informative commit messages. Else, if you are submitting on Canvas, make sure that the version you submit is the latest, and that it runs/knits without any errors.\nWhen you’re done, we should be able to knit the final version of the QMD in your GitHub as a HTML."
  },
  {
    "objectID": "assignments/index.html#load-packages",
    "href": "assignments/index.html#load-packages",
    "title": "ordinal regression",
    "section": "Load packages:",
    "text": "Load packages:\n\n\nCode\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(performance)\nlibrary(ordinal) #clm\nlibrary(car) # anova\nlibrary(ggeffects) #  viz\nlibrary(gofcat) # brant\nlibrary(brms)\nlibrary(emmeans) # contrasts\nlibrary(knitr)"
  },
  {
    "objectID": "assignments/index.html#load-data",
    "href": "assignments/index.html#load-data",
    "title": "ordinal regression",
    "section": "Load data",
    "text": "Load data\n\nMake sure only the top 3 ranks are being used. For some reason, there are missing ranks (my guess is they did not announce rank on TV)\n\n\n\nCode\ngbbo &lt;- read_csv(\"https://raw.githubusercontent.com/suyoghc/PSY-504_Spring-2025/refs/heads/main/Ordinal%20Regression/data/GBBO.csv\")\n\n# Enter code to filter. Think about the data type that would be relevant for Rank\ngb &lt;- gbbo %&gt;% \n  filter(!is.na(`Technical Rank`) & `Technical Rank` %in% c(1, 2, 3))"
  },
  {
    "objectID": "assignments/index.html#explore",
    "href": "assignments/index.html#explore",
    "title": "ordinal regression",
    "section": "Explore",
    "text": "Explore\n\nPlot two figures showing the percentage of bakers in each rank— create one for Gender and Age\n\n\nCode\n#plot percentage of bakers in each rank by gender\ngender_rank &lt;- gb %&gt;%\n  group_by(Gender, `Technical Rank`) %&gt;%\n  summarise(n = n(), .groups = 'drop') %&gt;%\n  mutate(perc = n / sum(n) * 100)\n\nggplot(gender_rank, aes(x = factor(`Technical Rank`), y = perc, fill = Gender)) +\n  geom_bar(stat = \"identity\", position = position_dodge(width = 0.8)) +\n  labs(title = \"Percentage of Bakers in Each Technical Rank by Gender\",\n   x = \"Technical Rank\",\n   y = \"Percentage\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n #plot percentage of bakers in each rank by age group\ngb &lt;- gb %&gt;% \n  mutate(AgeGroup = cut(Age, \n                        breaks = seq(floor(min(Age, na.rm = TRUE)), ceiling(max(Age, na.rm = TRUE)), by = 10),\n                        include.lowest = TRUE, right = FALSE))\n\nage_rank &lt;- gb %&gt;%\n  group_by(AgeGroup, `Technical Rank`) %&gt;%\n  summarise(n = n(), .groups = 'drop') %&gt;%\n  mutate(perc = n / sum(n) * 100)\n\nggplot(age_rank, aes(x = AgeGroup, y = perc, fill = factor(`Technical Rank`))) +\n  geom_bar(stat = \"identity\", position = position_dodge(width = 0.8)) +\n  labs(title = \"Percentage of Bakers in Each Technical Rank by Age Group\",\n       x = \"Age Group\",\n       y = \"Percentage\",\n       fill = \"Technical Rank\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\nCode\n#here's a plot without grouping age into bins, which is less informative visually so I prefer the above plot\nage_rank_cont &lt;- gb %&gt;%\n  group_by(Age, `Technical Rank`) %&gt;%\n  summarise(n = n(), .groups = 'drop') %&gt;%\n  \n  group_by(Age) %&gt;%\n  mutate(perc = n / sum(n) * 100) %&gt;%\n  ungroup()\n\nggplot(age_rank_cont, aes(x = factor(Age), y = perc, fill = factor(`Technical Rank`))) +\n  geom_bar(stat = \"identity\", position = position_dodge(width = 0.8)) +\n  labs(title = \"Percentage of Bakers in Each Technical Rank by Age\",\n       x = \"Age\",\n       y = \"Percentage\",\n       fill = \"Technical Rank\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
  },
  {
    "objectID": "assignments/index.html#ordinal-analysis",
    "href": "assignments/index.html#ordinal-analysis",
    "title": "ordinal regression",
    "section": "Ordinal Analysis",
    "text": "Ordinal Analysis\n\nIf you haven’t already, convert the outcome variable to an ordered factor. What does the order here represent?\n\n\nCode\n#The order now represents the ranking from best (1) to worst (3) among the top three.\ngb &lt;- gb %&gt;%\n  mutate(`Technical Rank` = factor(`Technical Rank`, levels = c(1, 2, 3), ordered = TRUE))\n\n\nConvert input variables to categorical factors as appropriate.\n\n\nCode\ngb &lt;- gb %&gt;%\n  mutate(Gender = factor(Gender, levels = c(\"M\", \"F\")))\n\n\nRun a ordinal logistic regression model against all relevant input variables. Interpret the effects for Gender, Age and Gender*Age (even if they are non-significant).\n\n\nCode\nmodel_int &lt;- clm(`Technical Rank` ~ Gender * Age, data = gb)\n\ntidy(model_int) %&gt;% kable(digits = 3)\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\ncoef.type\n\n\n\n\n1|2\n-0.267\n0.499\n-0.535\n0.593\nintercept\n\n\n2|3\n1.154\n0.504\n2.291\n0.022\nintercept\n\n\nGenderF\n1.149\n0.673\n1.708\n0.088\nlocation\n\n\nAge\n0.016\n0.014\n1.147\n0.252\nlocation\n\n\nGenderF:Age\n-0.039\n0.019\n-2.093\n0.036\nlocation\n\n\n\n\n\n\ninterpretation:\ngender: The coefficient for GenderF is 1.149 (p = 0.088). This means that, holding Age constant, females have a 1.149 unit higher latent score compared to males. Although this effect is only marginally significant (p = 0.088), it suggests that being female may be associated with a shift toward a higher rank category.\nage: The coefficient for Age is -0.013 (p = 0.000). This means that for each additional year of age, there is a 0.016 unit increase in the latent score. However, this effect is not statistically significant (p = 0.252), so we do not have strong evidence that Age alone affects technical rank.\ngenderxage: The interaction has an estimate of -0.039 (p = 0.036), which is statistically significant. This indicates that the effect of Age on technical rank differs by gender. Specifically, for females, the impact of Age is 0.039 units lower than for males.\n\nTest if the interaction is warranted\n\n#Hint: You need to create two models with clm(); one with interaction and one without. #Then you compare them using the anova test using anova()\n::: {.cell}\n\n```{.r .cell-code}\nmodel_int &lt;- clm(`Technical Rank` ~ Gender * Age, data = gb)\nmodel_no_int &lt;- clm(`Technical Rank` ~ Gender + Age, data = gb)\nanova(model_no_int, model_int)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLikelihood ratio tests of cumulative link models:\n \n             formula:                        link: threshold:\nmodel_no_int `Technical Rank` ~ Gender + Age logit flexible  \nmodel_int    `Technical Rank` ~ Gender * Age logit flexible  \n\n             no.par    AIC  logLik LR.stat df Pr(&gt;Chisq)  \nmodel_no_int      4 685.72 -338.86                        \nmodel_int         5 683.28 -336.64   4.437  1    0.03517 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n**interpretation: Including the Gender*Age interaction significantly improves the model (p &lt; .05), meaning that the effect of Age on the technical rank is different for different genders. In other words, the relationship between Age and technical rank depends on whether the baker is male or female.**\n\nUse ggemmeans to create a figure showing the interaction between Gender and Age as a function of rank. Plot predicted probabilities from the model.\n\n\nCode\ngb &lt;- gb %&gt;% rename(Technical_Rank = `Technical Rank`)\nmodel_int &lt;- clm(Technical_Rank ~ Gender * Age, data = gb)\npreds &lt;- ggemmeans(model_int, terms = c(\"Age [all]\", \"Gender\"), regrid = FALSE)\nplot(preds) +\n  labs(title = \"Predicted Probabilities for Technical_Rank by Age and Gender\",\n   x = \"Age\",\n   y = \"Predicted Probability\")\n\n\n\n\n\n\n\n\n\n\n\nLatent Visualization\n\n\nCode\nols_clm &lt;- MASS::polr(Technical_Rank ~ Gender * Age, data = gb)\n\nggeffect(ols_clm, terms = c(\"Age[all]\", \"Gender\"), latent = TRUE) %&gt;% \n  plot() +\n  labs(title = \"Effect of Age and Gender on Technical_Rank\",\n       x = \"Age\",\n       y = \"Latent Variable\")\n\n\n\n\n\n\n\n\n\n\nUse the Brant test to support or reject the hypothesis that the proportional odds assumption holds for your simplified model.\n\n\nCode\nbrant.test(ols_clm)\n\n\n\nBrant Test:\n               chi-sq   df   pr(&gt;chi)\nOmnibus         1.295    3       0.73\nGenderF         0.585    1       0.44\nAge             1.052    1       0.31\nGenderF:Age     0.924    1       0.34\n\nH0: Proportional odds assumption holds\n\n\n\nThe omnibus chi-square statistic is 1.295 with 3 degrees of freedom and a p-value of 0.73. Since this p-value is not significant, we do not reject the null hypothesis. This indicates that overall the proportional odds assumption holds for the model. None of the tests (including all the individual tests) are statistically significant, we conclude that there is no evidence to reject the null hypothesis. Thus, the proportional odds assumption holds for the simplified model.\n## `brms`\n\nBelow is a model implementation using the brms package. We will just use the default priors for this. The exercise is to run this code and note your observations. What are salient differences you observe in how the model fitting takes place With respect to the results, how do you compare the results of the model you fit with clm and the one you fit with brms?\n\n\n\nCode\n  ols2_brm &lt;- brm(Technical_Rank ~ Gender * Age, \n                  data = gb, \n                  family = cumulative, \n                  cores = 4, \n                  chains = 4, \n                  seed = 123)\n\n\nWhile both clm and brms provide very similar point estimates and conclusions regarding the effects of Gender, Age, and their interaction on Technical_Rank, the Bayesian approach (brms) offers richer information regarding uncertainty (CI) and additional convergence diagnostics.\n\nThe conditional_effects function is used to plot predicted probabilities by Gender and Age across each rank.\n::: {.cell}\n\nCode\nconditional_effects(ols2_brm, categorical = T)\n\n::: {.cell-output-display}  :::\n::: {.cell-output-display}  ::: :::\ncheck_predictions from the easystats performance package is used for examining model fit (i.e., does the data fit the model being used?). Run the below code. What do you think?\n\n\n\nCode\ncheck_predictions(ols2_brm)\n\n\n\n\n\n\n\n\n\nThis function shows how well the Bayesian model’s predictions align with the data. The green dots represent the actual counts (or frequencies) for each category of Technical_Rank in the dataset. The blue dots and error bars represent the mean (or median) model-predicted counts, while the error bars reflect the uncertainty (95% CI) around the predictions. The model predictions align fairly well with the actual data."
  },
  {
    "objectID": "assignments/ordinal_regression.html",
    "href": "assignments/ordinal_regression.html",
    "title": "ordinal regression",
    "section": "",
    "text": "If you are fitting a model, display the model output in a neatly formatted table. (The tidy and kable functions can help!)\nIf you are creating a plot, use clear labels for all axes, titles, etc.\nIf you are using Github, don’t forget to commit and push your work to to it regularly, at least after each exercise. Write short and informative commit messages. Else, if you are submitting on Canvas, make sure that the version you submit is the latest, and that it runs/knits without any errors.\nWhen you’re done, we should be able to knit the final version of the QMD in your GitHub as a HTML."
  },
  {
    "objectID": "assignments/ordinal_regression.html#instructions",
    "href": "assignments/ordinal_regression.html#instructions",
    "title": "ordinal regression",
    "section": "",
    "text": "If you are fitting a model, display the model output in a neatly formatted table. (The tidy and kable functions can help!)\nIf you are creating a plot, use clear labels for all axes, titles, etc.\nIf you are using Github, don’t forget to commit and push your work to to it regularly, at least after each exercise. Write short and informative commit messages. Else, if you are submitting on Canvas, make sure that the version you submit is the latest, and that it runs/knits without any errors.\nWhen you’re done, we should be able to knit the final version of the QMD in your GitHub as a HTML."
  },
  {
    "objectID": "assignments/ordinal_regression.html#load-packages",
    "href": "assignments/ordinal_regression.html#load-packages",
    "title": "ordinal regression",
    "section": "Load packages:",
    "text": "Load packages:\n\n\nCode\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(performance)\nlibrary(ordinal) #clm\nlibrary(car) # anova\nlibrary(ggeffects) #  viz\nlibrary(gofcat) # brant\nlibrary(brms)\nlibrary(emmeans) # contrasts\nlibrary(knitr)"
  },
  {
    "objectID": "assignments/ordinal_regression.html#load-data",
    "href": "assignments/ordinal_regression.html#load-data",
    "title": "ordinal regression",
    "section": "Load data",
    "text": "Load data\n\nMake sure only the top 3 ranks are being used. For some reason, there are missing ranks (my guess is they did not announce rank on TV)\n\n\n\nCode\ngbbo &lt;- read_csv(\"https://raw.githubusercontent.com/suyoghc/PSY-504_Spring-2025/refs/heads/main/Ordinal%20Regression/data/GBBO.csv\")\n\n# Enter code to filter. Think about the data type that would be relevant for Rank\ngb &lt;- gbbo %&gt;% \n  filter(!is.na(`Technical Rank`) & `Technical Rank` %in% c(1, 2, 3))"
  },
  {
    "objectID": "assignments/ordinal_regression.html#explore",
    "href": "assignments/ordinal_regression.html#explore",
    "title": "ordinal regression",
    "section": "Explore",
    "text": "Explore\n\nPlot two figures showing the percentage of bakers in each rank— create one for Gender and Age\n\n\nCode\n#plot percentage of bakers in each rank by gender\ngender_rank &lt;- gb %&gt;%\n  group_by(Gender, `Technical Rank`) %&gt;%\n  summarise(n = n(), .groups = 'drop') %&gt;%\n  mutate(perc = n / sum(n) * 100)\n\nggplot(gender_rank, aes(x = factor(`Technical Rank`), y = perc, fill = Gender)) +\n  geom_bar(stat = \"identity\", position = position_dodge(width = 0.8)) +\n  labs(title = \"Percentage of Bakers in Each Technical Rank by Gender\",\n   x = \"Technical Rank\",\n   y = \"Percentage\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n #plot percentage of bakers in each rank by age group\ngb &lt;- gb %&gt;% \n  mutate(AgeGroup = cut(Age, \n                        breaks = seq(floor(min(Age, na.rm = TRUE)), ceiling(max(Age, na.rm = TRUE)), by = 10),\n                        include.lowest = TRUE, right = FALSE))\n\nage_rank &lt;- gb %&gt;%\n  group_by(AgeGroup, `Technical Rank`) %&gt;%\n  summarise(n = n(), .groups = 'drop') %&gt;%\n  mutate(perc = n / sum(n) * 100)\n\nggplot(age_rank, aes(x = AgeGroup, y = perc, fill = factor(`Technical Rank`))) +\n  geom_bar(stat = \"identity\", position = position_dodge(width = 0.8)) +\n  labs(title = \"Percentage of Bakers in Each Technical Rank by Age Group\",\n       x = \"Age Group\",\n       y = \"Percentage\",\n       fill = \"Technical Rank\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\nCode\n#here's a plot without grouping age into bins, which is less informative visually so I prefer the above plot\nage_rank_cont &lt;- gb %&gt;%\n  group_by(Age, `Technical Rank`) %&gt;%\n  summarise(n = n(), .groups = 'drop') %&gt;%\n  \n  group_by(Age) %&gt;%\n  mutate(perc = n / sum(n) * 100) %&gt;%\n  ungroup()\n\nggplot(age_rank_cont, aes(x = factor(Age), y = perc, fill = factor(`Technical Rank`))) +\n  geom_bar(stat = \"identity\", position = position_dodge(width = 0.8)) +\n  labs(title = \"Percentage of Bakers in Each Technical Rank by Age\",\n       x = \"Age\",\n       y = \"Percentage\",\n       fill = \"Technical Rank\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
  },
  {
    "objectID": "assignments/ordinal_regression.html#ordinal-analysis",
    "href": "assignments/ordinal_regression.html#ordinal-analysis",
    "title": "ordinal regression",
    "section": "Ordinal Analysis",
    "text": "Ordinal Analysis\n\nIf you haven’t already, convert the outcome variable to an ordered factor. What does the order here represent?\n\n\nCode\n#The order now represents the ranking from best (1) to worst (3) among the top three.\ngb &lt;- gb %&gt;%\n  mutate(`Technical Rank` = factor(`Technical Rank`, levels = c(1, 2, 3), ordered = TRUE))\n\n\nConvert input variables to categorical factors as appropriate.\n\n\nCode\ngb &lt;- gb %&gt;%\n  mutate(Gender = factor(Gender, levels = c(\"M\", \"F\")))\n\n\nRun a ordinal logistic regression model against all relevant input variables. Interpret the effects for Gender, Age and Gender*Age (even if they are non-significant).\n\n\nCode\nmodel_int &lt;- clm(`Technical Rank` ~ Gender * Age, data = gb)\n\ntidy(model_int) %&gt;% kable(digits = 3)\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\ncoef.type\n\n\n\n\n1|2\n-0.267\n0.499\n-0.535\n0.593\nintercept\n\n\n2|3\n1.154\n0.504\n2.291\n0.022\nintercept\n\n\nGenderF\n1.149\n0.673\n1.708\n0.088\nlocation\n\n\nAge\n0.016\n0.014\n1.147\n0.252\nlocation\n\n\nGenderF:Age\n-0.039\n0.019\n-2.093\n0.036\nlocation\n\n\n\n\n\n\ninterpretation:\ngender: The coefficient for GenderF is 1.149 (p = 0.088). This means that, holding Age constant, females have a 1.149 unit higher latent score compared to males. Although this effect is only marginally significant (p = 0.088), it suggests that being female may be associated with a shift toward a higher rank category.\nage: The coefficient for Age is -0.013 (p = 0.000). This means that for each additional year of age, there is a 0.016 unit increase in the latent score. However, this effect is not statistically significant (p = 0.252), so we do not have strong evidence that Age alone affects technical rank.\ngenderxage: The interaction has an estimate of -0.039 (p = 0.036), which is statistically significant. This indicates that the effect of Age on technical rank differs by gender. Specifically, for females, the impact of Age is 0.039 units lower than for males.\n\nTest if the interaction is warranted\n\n#Hint: You need to create two models with clm(); one with interaction and one without. #Then you compare them using the anova test using anova()\n::: {.cell}\n\n```{.r .cell-code}\nmodel_int &lt;- clm(`Technical Rank` ~ Gender * Age, data = gb)\nmodel_no_int &lt;- clm(`Technical Rank` ~ Gender + Age, data = gb)\nanova(model_no_int, model_int)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLikelihood ratio tests of cumulative link models:\n \n             formula:                        link: threshold:\nmodel_no_int `Technical Rank` ~ Gender + Age logit flexible  \nmodel_int    `Technical Rank` ~ Gender * Age logit flexible  \n\n             no.par    AIC  logLik LR.stat df Pr(&gt;Chisq)  \nmodel_no_int      4 685.72 -338.86                        \nmodel_int         5 683.28 -336.64   4.437  1    0.03517 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n**interpretation: Including the Gender*Age interaction significantly improves the model (p &lt; .05), meaning that the effect of Age on the technical rank is different for different genders. In other words, the relationship between Age and technical rank depends on whether the baker is male or female.**\n\nUse ggemmeans to create a figure showing the interaction between Gender and Age as a function of rank. Plot predicted probabilities from the model.\n\n\nCode\ngb &lt;- gb %&gt;% rename(Technical_Rank = `Technical Rank`)\nmodel_int &lt;- clm(Technical_Rank ~ Gender * Age, data = gb)\npreds &lt;- ggemmeans(model_int, terms = c(\"Age [all]\", \"Gender\"), regrid = FALSE)\nplot(preds) +\n  labs(title = \"Predicted Probabilities for Technical_Rank by Age and Gender\",\n   x = \"Age\",\n   y = \"Predicted Probability\")\n\n\n\n\n\n\n\n\n\n\n\nLatent Visualization\n\n\nCode\nols_clm &lt;- MASS::polr(Technical_Rank ~ Gender * Age, data = gb)\n\nggeffect(ols_clm, terms = c(\"Age[all]\", \"Gender\"), latent = TRUE) %&gt;% \n  plot() +\n  labs(title = \"Effect of Age and Gender on Technical_Rank\",\n       x = \"Age\",\n       y = \"Latent Variable\")\n\n\n\n\n\n\n\n\n\n\nUse the Brant test to support or reject the hypothesis that the proportional odds assumption holds for your simplified model.\n\n\nCode\nbrant.test(ols_clm)\n\n\n\nBrant Test:\n               chi-sq   df   pr(&gt;chi)\nOmnibus         1.295    3       0.73\nGenderF         0.585    1       0.44\nAge             1.052    1       0.31\nGenderF:Age     0.924    1       0.34\n\nH0: Proportional odds assumption holds\n\n\n\nThe omnibus chi-square statistic is 1.295 with 3 degrees of freedom and a p-value of 0.73. Since this p-value is not significant, we do not reject the null hypothesis. This indicates that overall the proportional odds assumption holds for the model. None of the tests (including all the individual tests) are statistically significant, we conclude that there is no evidence to reject the null hypothesis. Thus, the proportional odds assumption holds for the simplified model.\n## `brms`\n\nBelow is a model implementation using the brms package. We will just use the default priors for this. The exercise is to run this code and note your observations. What are salient differences you observe in how the model fitting takes place With respect to the results, how do you compare the results of the model you fit with clm and the one you fit with brms?\n\n\n\nCode\n  ols2_brm &lt;- brm(Technical_Rank ~ Gender * Age, \n                  data = gb, \n                  family = cumulative, \n                  cores = 4, \n                  chains = 4, \n                  seed = 123)\n\n\nWhile both clm and brms provide very similar point estimates and conclusions regarding the effects of Gender, Age, and their interaction on Technical_Rank, the Bayesian approach (brms) offers richer information regarding uncertainty (CI) and additional convergence diagnostics.\n\nThe conditional_effects function is used to plot predicted probabilities by Gender and Age across each rank.\n::: {.cell}\n\nCode\nconditional_effects(ols2_brm, categorical = T)\n\n::: {.cell-output-display}  :::\n::: {.cell-output-display}  ::: :::\ncheck_predictions from the easystats performance package is used for examining model fit (i.e., does the data fit the model being used?). Run the below code. What do you think?\n\n\n\nCode\ncheck_predictions(ols2_brm)\n\n\n\n\n\n\n\n\n\nThis function shows how well the Bayesian model’s predictions align with the data. The green dots represent the actual counts (or frequencies) for each category of Technical_Rank in the dataset. The blue dots and error bars represent the mean (or median) model-predicted counts, while the error bars reflect the uncertainty (95% CI) around the predictions. The model predictions align fairly well with the actual data."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  }
]